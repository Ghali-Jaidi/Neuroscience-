{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b741cf03",
   "metadata": {},
   "source": [
    "# Training and testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a953d",
   "metadata": {},
   "source": [
    "We train and test different models that perform classification tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26b0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "#%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9116c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a47571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Part1_Results: (232, 9)\n",
      "Loaded Part2_Results: (232, 16)\n",
      "Loaded Part3_Results: (134, 16)\n"
     ]
    }
   ],
   "source": [
    "base_dir = '.' \n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "files = ['Part1_Results.csv', 'Part2_Results.csv', 'Part3_Results.csv']\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        # Extract name without extension for dictionary key\n",
    "        name = file.replace('.csv', '')\n",
    "        dataframes[name] = pd.read_csv(file_path, sep=';', index_col=0)\n",
    "        print(f\"Loaded {name}: {dataframes[name].shape}\")\n",
    "    else:\n",
    "        print(f\"Warning: {file} not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9f5ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 columns: ['numb_events', 'wp_avg', 'wp_amplitude_pre', 'wp_amplitude_post', 'vm_avg', 'vm_amplitude_pre', 'vm_amplitude_post', 'ap_avg', 'ap_psth', 'ap_fr_pre', 'ap_fr_post', 'delta_wp', 'delta_vm', 'delta_ap']\n"
     ]
    }
   ],
   "source": [
    "X_1 = dataframes['Part1_Results'].copy()\n",
    "X_1.drop(columns=['cell_id', 'cell_type'], inplace=True)\n",
    "y_1 = dataframes['Part1_Results']['cell_type'].copy()\n",
    "label_encoder = LabelEncoder()\n",
    "y_1 = label_encoder.fit_transform(y_1)\n",
    "\n",
    "if X_1['ap_duration'].isna().any():\n",
    "    median_val = X_1['ap_duration'].median()\n",
    "    X_1.loc[:, 'ap_duration'] = X_1['ap_duration'].fillna(median_val)\n",
    "\n",
    "X_2 = dataframes['Part2_Results'].copy()\n",
    "X_2.drop(columns=['cell_id', 'cell_type'], inplace=True)\n",
    "y_2 = dataframes['Part2_Results']['cell_type'].copy()\n",
    "y_2 = label_encoder.fit_transform(y_2)\n",
    "\n",
    "X_3 = dataframes['Part3_Results'].copy()\n",
    "X_3.drop(columns=['cell_id', 'cell_type'], inplace=True)\n",
    "y_3 = dataframes['Part3_Results']['cell_type'].copy()\n",
    "y_3 = label_encoder.fit_transform(y_3)  \n",
    "\n",
    "print(\"X_2 columns:\", X_2.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d2fb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X_1, y_1, \n",
    "    test_size=0.2, \n",
    "    stratify=y_1,  #ensures percentages of cell types are preserved\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(\n",
    "    X_3, y_3, \n",
    "    test_size=0.2, \n",
    "    stratify=y_3,  \n",
    "    random_state=42  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acdbe4",
   "metadata": {},
   "source": [
    "Now, we define the superdataset that comprises the features from the first and second parts only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29d1d3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superdataset shape: (232, 21)\n"
     ]
    }
   ],
   "source": [
    "# Build a \"superdataset\" with shared cell_ids across Part1/2/3, dropping the 8 Part3-only cells.\n",
    "common_ids = (\n",
    "    set(dataframes[\"Part1_Results\"][\"cell_id\"])\n",
    "    & set(dataframes[\"Part2_Results\"][\"cell_id\"])\n",
    ")\n",
    "\n",
    "def _prep_part(df, prefix):\n",
    "    tmp = df[df[\"cell_id\"].isin(common_ids)].copy()\n",
    "    tmp = tmp.set_index(\"cell_id\")\n",
    "    y = tmp[\"cell_type\"].copy()\n",
    "    X = tmp.drop(columns=[\"cell_type\"])\n",
    "    X = X.add_prefix(f\"{prefix}__\")\n",
    "    return X, y\n",
    "\n",
    "X1s, y1s = _prep_part(dataframes[\"Part1_Results\"], \"P1\")\n",
    "X2s, y2s = _prep_part(dataframes[\"Part2_Results\"], \"P2\")\n",
    "\n",
    "# Safety check: cell_type should match across parts for the shared ids\n",
    "X_super = X1s.join([X2s], how=\"inner\")\n",
    "y_super = label_encoder.fit_transform(y1s)\n",
    "\n",
    "print(\"Superdataset shape:\", X_super.shape)\n",
    "\n",
    "\n",
    "# Handle NaNs similarly to Part1 ap_duration treatment\n",
    "if \"P1__ap_duration\" in X_super.columns and X_super[\"P1__ap_duration\"].isna().any():\n",
    "    X_super.loc[:, \"P1__ap_duration\"] = X_super[\"P1__ap_duration\"].fillna(X_super[\"P1__ap_duration\"].median())\n",
    "\n",
    "X_trainS, X_testS, y_trainS, y_testS = train_test_split(\n",
    "    X_super, y_super, test_size=0.2, stratify=y_super, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fff02",
   "metadata": {},
   "source": [
    "We define a function that will be used to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "423f5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, dataset_name=\"\", scale=False):    \n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred, \n",
    "                                   target_names=label_encoder.classes_,\n",
    "                                   output_dict=True)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'dataset': dataset_name,\n",
    "        'model': model.__class__.__name__,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'n_features': X_train.shape[1],\n",
    "        'report': report,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1097b92",
   "metadata": {},
   "source": [
    "## Model training and testing on Part 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38628137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65ea0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to train and test\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)),\n",
    "    ('SVM Linear', SVC(kernel='linear', class_weight='balanced', random_state=42)),\n",
    "    ('SVM RBF', SVC(kernel='rbf', class_weight='balanced', random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, max_depth=5, \n",
    "                                             class_weight='balanced', random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, max_depth=3, \n",
    "                                                     random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5cefa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Testing Logistic Regression-------\n",
      "Accuracy: 0.830, F1-macro: 0.789\n",
      "confusion matrix:\n",
      "[[16  0  0  1]\n",
      " [ 0  8  2  0]\n",
      " [ 2  0 12  1]\n",
      " [ 0  1  1  3]]\n",
      "-------Testing SVM Linear-------\n",
      "Accuracy: 0.851, F1-macro: 0.805\n",
      "confusion matrix:\n",
      "[[16  0  0  1]\n",
      " [ 0  8  2  0]\n",
      " [ 1  0 13  1]\n",
      " [ 0  1  1  3]]\n",
      "-------Testing SVM RBF-------\n",
      "Accuracy: 0.830, F1-macro: 0.765\n",
      "confusion matrix:\n",
      "[[17  0  0  0]\n",
      " [ 0  8  2  0]\n",
      " [ 2  0 12  1]\n",
      " [ 0  1  2  2]]\n",
      "-------Testing Random Forest-------\n",
      "Accuracy: 0.851, F1-macro: 0.782\n",
      "confusion matrix:\n",
      "[[17  0  0  0]\n",
      " [ 0  8  2  0]\n",
      " [ 1  0 13  1]\n",
      " [ 0  1  2  2]]\n",
      "-------Testing Gradient Boosting-------\n",
      "Accuracy: 0.851, F1-macro: 0.781\n",
      "confusion matrix:\n",
      "[[17  0  0  0]\n",
      " [ 0  8  2  0]\n",
      " [ 1  0 13  1]\n",
      " [ 1  1  1  2]]\n",
      "-------Testing KNN-------\n",
      "Accuracy: 0.830, F1-macro: 0.727\n",
      "confusion matrix:\n",
      "[[17  0  0  0]\n",
      " [ 0  8  2  0]\n",
      " [ 2  0 13  0]\n",
      " [ 0  1  3  1]]\n",
      "SUMMARY OF ALL RESULTS:\n",
      "  dataset                       model  accuracy  f1_macro  n_features\n",
      "0   Part1          LogisticRegression  0.829787  0.789098           7\n",
      "1   Part1                         SVC  0.851064  0.805498           7\n",
      "2   Part1                         SVC  0.829787  0.765186           7\n",
      "3   Part1      RandomForestClassifier  0.851064  0.781508           7\n",
      "4   Part1  GradientBoostingClassifier  0.851064  0.781315           7\n",
      "5   Part1        KNeighborsClassifier  0.829787  0.726940           7\n"
     ]
    }
   ],
   "source": [
    "# We test each model first on the data from Part 1\n",
    "all_results = []\n",
    "\n",
    "for model_name, model in models:\n",
    "\n",
    "    print(f\"-------Testing {model_name}-------\")\n",
    "\n",
    "    \n",
    "    res1, _ = evaluate_model(model, X_train1, X_test1, y_train1, y_test1, \n",
    "                            dataset_name=\"Part1\", scale=True)\n",
    "    all_results.append(res1)\n",
    "    print(f\"Accuracy: {res1['accuracy']:.3f}, F1-macro: {res1['f1_macro']:.3f}\")\n",
    "    print(f\"confusion matrix:\")\n",
    "    print(res1['confusion_matrix'])\n",
    "\n",
    "\n",
    "# Convert results to DataFrame for comparison\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"SUMMARY OF ALL RESULTS:\")\n",
    "\n",
    "print(results_df[['dataset', 'model', 'accuracy', 'f1_macro', 'n_features']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c435d",
   "metadata": {},
   "source": [
    "Now we do the same for part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "086623da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['numb_events', 'wp_avg', 'wp_amplitude_pre', 'wp_amplitude_post',\n",
      "       'vm_avg', 'vm_amplitude_pre', 'vm_amplitude_post', 'ap_avg', 'ap_psth',\n",
      "       'ap_fr_pre', 'ap_fr_post', 'delta_wp', 'delta_vm', 'delta_ap'],\n",
      "      dtype='object')\n",
      "\n",
      "============================================================\n",
      "Testing Logistic Regression\n",
      "============================================================\n",
      "Accuracy: 0.587, F1-macro: 0.561\n",
      "\n",
      "============================================================\n",
      "Testing SVM Linear\n",
      "============================================================\n",
      "Accuracy: 0.652, F1-macro: 0.637\n",
      "\n",
      "============================================================\n",
      "Testing SVM RBF\n",
      "============================================================\n",
      "Accuracy: 0.739, F1-macro: 0.698\n",
      "\n",
      "============================================================\n",
      "Testing Random Forest\n",
      "============================================================\n",
      "Accuracy: 0.761, F1-macro: 0.774\n",
      "\n",
      "============================================================\n",
      "Testing Gradient Boosting\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/nl1hl3ps5wj29xvjztgntggw0000gn/T/ipykernel_3851/3636859624.py:12: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  return np.fromstring(s, sep=' ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.761, F1-macro: 0.758\n",
      "\n",
      "============================================================\n",
      "Testing KNN\n",
      "============================================================\n",
      "Accuracy: 0.739, F1-macro: 0.692\n",
      "SUMMARY OF ALL RESULTS:\n",
      "   dataset                       model  accuracy  f1_macro  n_features\n",
      "0    Part1          LogisticRegression  0.829787  0.789098           7\n",
      "1    Part1                         SVC  0.851064  0.805498           7\n",
      "2    Part1                         SVC  0.829787  0.765186           7\n",
      "3    Part1      RandomForestClassifier  0.851064  0.781508           7\n",
      "4    Part1  GradientBoostingClassifier  0.851064  0.781315           7\n",
      "5    Part1        KNeighborsClassifier  0.829787  0.726940           7\n",
      "6    Part2          LogisticRegression  0.586957  0.561466          24\n",
      "7    Part2                         SVC  0.652174  0.636732          24\n",
      "8    Part2                         SVC  0.739130  0.698321          24\n",
      "9    Part2      RandomForestClassifier  0.760870  0.774296          24\n",
      "10   Part2  GradientBoostingClassifier  0.760870  0.758180          24\n",
      "11   Part2        KNeighborsClassifier  0.739130  0.691764          24\n"
     ]
    }
   ],
   "source": [
    "#Part 2 has vector features, we need to convert them to fixed-size features first.\n",
    "def parse_vec(s: str) -> np.ndarray:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return np.array([])\n",
    "    s = str(s).strip()\n",
    "    # remove brackets if present\n",
    "    if s.startswith('[') and s.endswith(']'):\n",
    "        s = s[1:-1]\n",
    "    # make commas behave like spaces\n",
    "    s = s.replace(',', ' ')\n",
    "    # parse numbers\n",
    "    return np.fromstring(s, sep=' ')\n",
    "\n",
    "# Apply parsing to vector features in Part 2\n",
    "vector_features = ['wp_avg', 'vm_avg', 'ap_avg', 'ap_psth']\n",
    "print(X_2.columns)\n",
    "for feature in vector_features:\n",
    "    X_2[feature] = X_2[feature].apply(parse_vec)\n",
    "\n",
    "# Now compute summary statistics for each vector feature\n",
    "X_2[\"P2__wp_avg_mean\"] = X_2[\"wp_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "X_2[\"P2__wp_avg_std\"]  = X_2[\"wp_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "X_2[\"P2__wp_avg_min\"]  = X_2[\"wp_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "X_2[\"P2__wp_avg_max\"]  = X_2[\"wp_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "X_2[\"P2__vm_avg_mean\"] = X_2[\"vm_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "X_2[\"P2__vm_avg_std\"]  = X_2[\"vm_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "X_2[\"P2__ap_avg_mean\"] = X_2[\"ap_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "X_2[\"P2__ap_avg_std\"]  = X_2[\"ap_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "X_2[\"P2__ap_avg_min\"]  = X_2[\"ap_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "X_2[\"P2__ap_avg_max\"]  = X_2[\"ap_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)    \n",
    "X_2[\"P2__ap_psth_mean\"] = X_2[\"ap_psth\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "X_2[\"P2__ap_psth_std\"]  = X_2[\"ap_psth\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "X_2[\"P2__ap_psth_min\"]  = X_2[\"ap_psth\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "X_2[\"P2__ap_psth_max\"]  = X_2[\"ap_psth\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "\n",
    "# Drop original vector features\n",
    "for feature in vector_features : \n",
    "    X_2 = X_2.drop(columns=[feature])\n",
    "\n",
    "# Handle any remaining NaNs by removing the corresponding rows. (After manual checking the problematic rows show no data at all)\n",
    "\n",
    "# Drop rows with NaNs in X_2 and drop the corresponding labels in y_2\n",
    "mask = X_2.notna().all(axis=1)\n",
    "X_2 = X_2.loc[mask].copy()\n",
    "y_2 = y_2[mask.values]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X_2, y_2, \n",
    "    test_size=0.2, \n",
    "    stratify=y_2,  \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "for model_name, model in models:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {model_name}\")\n",
    "    print('='*60)\n",
    "\n",
    "    res1, _ = evaluate_model(model, X_train2, X_test2, y_train2, y_test2, \n",
    "                            dataset_name=\"Part2\", scale=True)\n",
    "    all_results.append(res1)\n",
    "    print(f\"Accuracy: {res1['accuracy']:.3f}, F1-macro: {res1['f1_macro']:.3f}\")\n",
    "\n",
    "\n",
    "# Convert results to DataFrame for comparison\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"SUMMARY OF ALL RESULTS:\")\n",
    "\n",
    "print(results_df[['dataset', 'model', 'accuracy', 'f1_macro', 'n_features']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea391b9",
   "metadata": {},
   "source": [
    "Now let's compute the metrics for the super dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62dc6c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing Logistic Regression\n",
      "============================================================\n",
      "Accuracy: 0.870, F1-macro: 0.858\n",
      "\n",
      "============================================================\n",
      "Testing SVM Linear\n",
      "============================================================\n",
      "Accuracy: 0.783, F1-macro: 0.762\n",
      "\n",
      "============================================================\n",
      "Testing SVM RBF\n",
      "============================================================\n",
      "Accuracy: 0.913, F1-macro: 0.886\n",
      "\n",
      "============================================================\n",
      "Testing Random Forest\n",
      "============================================================\n",
      "Accuracy: 0.783, F1-macro: 0.714\n",
      "\n",
      "============================================================\n",
      "Testing Gradient Boosting\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/nl1hl3ps5wj29xvjztgntggw0000gn/T/ipykernel_3851/2476337168.py:9: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  return np.fromstring(s, sep=' ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.913, F1-macro: 0.889\n",
      "\n",
      "============================================================\n",
      "Testing KNN\n",
      "============================================================\n",
      "Accuracy: 0.891, F1-macro: 0.830\n",
      "SUMMARY OF ALL RESULTS:\n",
      "        dataset                       model  accuracy  f1_macro  n_features\n",
      "0         Part1          LogisticRegression  0.829787  0.789098           7\n",
      "1         Part1                         SVC  0.851064  0.805498           7\n",
      "2         Part1                         SVC  0.829787  0.765186           7\n",
      "3         Part1      RandomForestClassifier  0.851064  0.781508           7\n",
      "4         Part1  GradientBoostingClassifier  0.851064  0.781315           7\n",
      "5         Part1        KNeighborsClassifier  0.829787  0.726940           7\n",
      "6         Part2          LogisticRegression  0.586957  0.561466          24\n",
      "7         Part2                         SVC  0.652174  0.636732          24\n",
      "8         Part2                         SVC  0.739130  0.698321          24\n",
      "9         Part2      RandomForestClassifier  0.760870  0.774296          24\n",
      "10        Part2  GradientBoostingClassifier  0.760870  0.758180          24\n",
      "11        Part2        KNeighborsClassifier  0.739130  0.691764          24\n",
      "12  Part1+Part2          LogisticRegression  0.869565  0.858278          31\n",
      "13  Part1+Part2                         SVC  0.782609  0.761762          31\n",
      "14  Part1+Part2                         SVC  0.913043  0.886284          31\n",
      "15  Part1+Part2      RandomForestClassifier  0.782609  0.713757          31\n",
      "16  Part1+Part2  GradientBoostingClassifier  0.913043  0.889217          31\n",
      "17  Part1+Part2        KNeighborsClassifier  0.891304  0.829762          31\n"
     ]
    }
   ],
   "source": [
    "# --- Replicate Part2 preprocessing for vector features inside the superdataset ---\n",
    "def parse_vec(s: str) -> np.ndarray:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return np.array([])\n",
    "    s = str(s).strip()\n",
    "    if s.startswith('[') and s.endswith(']'):\n",
    "        s = s[1:-1]\n",
    "    s = s.replace(',', ' ')\n",
    "    return np.fromstring(s, sep=' ')\n",
    "\n",
    "# Identify the P2 vector-like columns in X_super (they were prefixed earlier)\n",
    "p2_vec_cols = [\"P2__wp_avg\", \"P2__vm_avg\", \"P2__ap_avg\", \"P2__ap_psth\"]\n",
    "p2_vec_cols = [c for c in p2_vec_cols if c in X_super.columns]\n",
    "\n",
    "# Parse vectors from strings -> np.ndarray\n",
    "for c in p2_vec_cols:\n",
    "    X_super[c] = X_super[c].apply(parse_vec)\n",
    "\n",
    "# Create fixed-size summary stats (same behavior as Part2 cell)\n",
    "if \"P2__wp_avg\" in X_super.columns:\n",
    "    X_super[\"P2__wp_avg_mean\"] = X_super[\"P2__wp_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super[\"P2__wp_avg_std\"]  = X_super[\"P2__wp_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super[\"P2__wp_avg_min\"]  = X_super[\"P2__wp_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super[\"P2__wp_avg_max\"]  = X_super[\"P2__wp_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P2__vm_avg\" in X_super.columns:\n",
    "    X_super[\"P2__vm_avg_mean\"] = X_super[\"P2__vm_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super[\"P2__vm_avg_std\"]  = X_super[\"P2__vm_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P2__ap_avg\" in X_super.columns:\n",
    "    X_super[\"P2__ap_avg_mean\"] = X_super[\"P2__ap_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super[\"P2__ap_avg_std\"]  = X_super[\"P2__ap_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super[\"P2__ap_avg_min\"]  = X_super[\"P2__ap_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super[\"P2__ap_avg_max\"]  = X_super[\"P2__ap_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P2__ap_psth\" in X_super.columns:\n",
    "    X_super[\"P2__ap_psth_mean\"] = X_super[\"P2__ap_psth\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super[\"P2__ap_psth_std\"]  = X_super[\"P2__ap_psth\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super[\"P2__ap_psth_min\"]  = X_super[\"P2__ap_psth\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super[\"P2__ap_psth_max\"]  = X_super[\"P2__ap_psth\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "# Drop original vector columns\n",
    "if p2_vec_cols:\n",
    "    X_super = X_super.drop(columns=p2_vec_cols)\n",
    "\n",
    "# Handle NaNs like in Part2: drop rows with any NaN and align y\n",
    "mask = X_super.notna().all(axis=1)\n",
    "X_super = X_super.loc[mask].copy()\n",
    "y_super = y_super[mask.values]\n",
    "\n",
    "# Recreate the split for the cleaned superdataset\n",
    "X_trainS, X_testS, y_trainS, y_testS = train_test_split(\n",
    "    X_super, y_super, test_size=0.2, stratify=y_super, random_state=42\n",
    ")\n",
    "\n",
    "# Keep Part1-style NaN handling for ap_duration if present (no-op if already clean)\n",
    "if \"P1__ap_duration\" in X_super.columns and X_super[\"P1__ap_duration\"].isna().any():\n",
    "    X_super.loc[:, \"P1__ap_duration\"] = X_super[\"P1__ap_duration\"].fillna(X_super[\"P1__ap_duration\"].median())\n",
    "for model_name, model in models:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {model_name}\")\n",
    "    print('='*60)\n",
    "\n",
    "    res1, _ = evaluate_model(model, X_trainS, X_testS, y_trainS, y_testS, \n",
    "                            dataset_name=\"Part1+Part2\", scale=True)\n",
    "    all_results.append(res1)\n",
    "    print(f\"Accuracy: {res1['accuracy']:.3f}, F1-macro: {res1['f1_macro']:.3f}\")\n",
    "\n",
    "\n",
    "# Convert results to DataFrame for comparison\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"SUMMARY OF ALL RESULTS:\")\n",
    "\n",
    "print(results_df[['dataset', 'model', 'accuracy', 'f1_macro', 'n_features']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558cb035",
   "metadata": {},
   "source": [
    "Comparing the best possible accuracy across the different datasets the models use, we cn see that the super dataset always has at least one model with a better accuracy. \n",
    "\n",
    "Now, let's try with the 3rd part as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e3759fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superdataset (Part1+Part2+Part3) shape before preprocessing: (126, 35)\n",
      "Superdataset (Part1+Part2+Part3) shape after preprocessing: (123, 57)\n",
      "\n",
      "============================================================\n",
      "Testing Logistic Regression\n",
      "============================================================\n",
      "Accuracy: 0.960, F1-macro: 0.900\n",
      "\n",
      "============================================================\n",
      "Testing SVM Linear\n",
      "============================================================\n",
      "Accuracy: 0.960, F1-macro: 0.900\n",
      "\n",
      "============================================================\n",
      "Testing SVM RBF\n",
      "============================================================\n",
      "Accuracy: 0.960, F1-macro: 0.900\n",
      "\n",
      "============================================================\n",
      "Testing Random Forest\n",
      "============================================================\n",
      "Accuracy: 0.840, F1-macro: 0.645\n",
      "\n",
      "============================================================\n",
      "Testing Gradient Boosting\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/nl1hl3ps5wj29xvjztgntggw0000gn/T/ipykernel_3851/2476337168.py:9: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  return np.fromstring(s, sep=' ')\n",
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.920, F1-macro: 0.943\n",
      "\n",
      "============================================================\n",
      "Testing KNN\n",
      "============================================================\n",
      "Accuracy: 0.920, F1-macro: 0.706\n",
      "SUMMARY OF ALL RESULTS:\n",
      "              dataset                       model  accuracy  f1_macro  \\\n",
      "0               Part1          LogisticRegression  0.829787  0.789098   \n",
      "1               Part1                         SVC  0.851064  0.805498   \n",
      "2               Part1                         SVC  0.829787  0.765186   \n",
      "3               Part1      RandomForestClassifier  0.851064  0.781508   \n",
      "4               Part1  GradientBoostingClassifier  0.851064  0.781315   \n",
      "5               Part1        KNeighborsClassifier  0.829787  0.726940   \n",
      "6               Part2          LogisticRegression  0.586957  0.561466   \n",
      "7               Part2                         SVC  0.652174  0.636732   \n",
      "8               Part2                         SVC  0.739130  0.698321   \n",
      "9               Part2      RandomForestClassifier  0.760870  0.774296   \n",
      "10              Part2  GradientBoostingClassifier  0.760870  0.758180   \n",
      "11              Part2        KNeighborsClassifier  0.739130  0.691764   \n",
      "12        Part1+Part2          LogisticRegression  0.869565  0.858278   \n",
      "13        Part1+Part2                         SVC  0.782609  0.761762   \n",
      "14        Part1+Part2                         SVC  0.913043  0.886284   \n",
      "15        Part1+Part2      RandomForestClassifier  0.782609  0.713757   \n",
      "16        Part1+Part2  GradientBoostingClassifier  0.913043  0.889217   \n",
      "17        Part1+Part2        KNeighborsClassifier  0.891304  0.829762   \n",
      "18  Part1+Part2+Part3          LogisticRegression  0.960000  0.900000   \n",
      "19  Part1+Part2+Part3                         SVC  0.960000  0.900000   \n",
      "20  Part1+Part2+Part3                         SVC  0.960000  0.900000   \n",
      "21  Part1+Part2+Part3      RandomForestClassifier  0.840000  0.645299   \n",
      "22  Part1+Part2+Part3  GradientBoostingClassifier  0.920000  0.943452   \n",
      "23  Part1+Part2+Part3        KNeighborsClassifier  0.920000  0.705556   \n",
      "\n",
      "    n_features  \n",
      "0            7  \n",
      "1            7  \n",
      "2            7  \n",
      "3            7  \n",
      "4            7  \n",
      "5            7  \n",
      "6           24  \n",
      "7           24  \n",
      "8           24  \n",
      "9           24  \n",
      "10          24  \n",
      "11          24  \n",
      "12          31  \n",
      "13          31  \n",
      "14          31  \n",
      "15          31  \n",
      "16          31  \n",
      "17          31  \n",
      "18          57  \n",
      "19          57  \n",
      "20          57  \n",
      "21          57  \n",
      "22          57  \n",
      "23          57  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# --- Build a new superdataset that includes Part1 + Part2 + Part3 (shared cell_ids only) ---\n",
    "\n",
    "common_ids_123 = (\n",
    "    set(dataframes[\"Part1_Results\"][\"cell_id\"])\n",
    "    & set(dataframes[\"Part2_Results\"][\"cell_id\"])\n",
    "    & set(dataframes[\"Part3_Results\"][\"cell_id\"])\n",
    ")\n",
    "\n",
    "def _prep_part(df, prefix, ids):\n",
    "    tmp = df[df[\"cell_id\"].isin(ids)].copy().set_index(\"cell_id\")\n",
    "    y = tmp[\"cell_type\"].copy()\n",
    "    X = tmp.drop(columns=[\"cell_type\"])\n",
    "    X = X.add_prefix(f\"{prefix}__\")\n",
    "    return X, y\n",
    "\n",
    "X1s_123, y1s_123 = _prep_part(dataframes[\"Part1_Results\"], \"P1\", common_ids_123)\n",
    "X2s_123, y2s_123 = _prep_part(dataframes[\"Part2_Results\"], \"P2\", common_ids_123)\n",
    "X3s_123, y3s_123 = _prep_part(dataframes[\"Part3_Results\"], \"P3\", common_ids_123)\n",
    "\n",
    "X_super123 = X1s_123.join([X2s_123, X3s_123], how=\"inner\")\n",
    "y_super123 = label_encoder.fit_transform(y1s_123)\n",
    "\n",
    "print(\"Superdataset (Part1+Part2+Part3) shape before preprocessing:\", X_super123.shape)\n",
    "\n",
    "# --- Part2 vector-feature preprocessing inside the new superdataset (same logic as before) ---\n",
    "vec_cols = [\"P2__wp_avg\", \"P2__vm_avg\", \"P2__ap_avg\", \"P2__ap_psth\", \"P3__wp_avg\", \"P3__vm_avg\", \"P3__ap_avg\", \"P3__ap_psth\"]\n",
    "vec_cols = [c for c in vec_cols if c in X_super123.columns]\n",
    "\n",
    "\n",
    "for c in vec_cols:\n",
    "    X_super123[c] = X_super123[c].apply(parse_vec)\n",
    "\n",
    "if \"P2__wp_avg\" in X_super123.columns:\n",
    "    X_super123[\"P2__wp_avg_mean\"] = X_super123[\"P2__wp_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super123[\"P2__wp_avg_std\"]  = X_super123[\"P2__wp_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super123[\"P2__wp_avg_min\"]  = X_super123[\"P2__wp_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super123[\"P2__wp_avg_max\"]  = X_super123[\"P2__wp_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P2__vm_avg\" in X_super123.columns:\n",
    "    X_super123[\"P2__vm_avg_mean\"] = X_super123[\"P2__vm_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super123[\"P2__vm_avg_std\"]  = X_super123[\"P2__vm_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P2__ap_avg\" in X_super123.columns:\n",
    "    X_super123[\"P2__ap_avg_mean\"] = X_super123[\"P2__ap_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super123[\"P2__ap_avg_std\"]  = X_super123[\"P2__ap_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super123[\"P2__ap_avg_min\"]  = X_super123[\"P2__ap_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super123[\"P2__ap_avg_max\"]  = X_super123[\"P2__ap_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P2__ap_psth\" in X_super123.columns:\n",
    "    X_super123[\"P2__ap_psth_mean\"] = X_super123[\"P2__ap_psth\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super123[\"P2__ap_psth_std\"]  = X_super123[\"P2__ap_psth\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super123[\"P2__ap_psth_min\"]  = X_super123[\"P2__ap_psth\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super123[\"P2__ap_psth_max\"]  = X_super123[\"P2__ap_psth\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P3__wp_avg\" in X_super123.columns:\n",
    "    X_super123[\"P3__wp_avg_mean\"] = X_super123[\"P3__wp_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super123[\"P3__wp_avg_std\"]  = X_super123[\"P3__wp_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super123[\"P3__wp_avg_min\"]  = X_super123[\"P3__wp_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super123[\"P3__wp_avg_max\"]  = X_super123[\"P3__wp_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P3__vm_avg\" in X_super123.columns:\n",
    "    X_super123[\"P3__vm_avg_mean\"] = X_super123[\"P3__vm_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super123[\"P3__vm_avg_std\"]  = X_super123[\"P3__vm_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super123[\"P3__vm_avg_min\"]  = X_super123[\"P3__vm_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super123[\"P3__vm_avg_max\"]  = X_super123[\"P3__vm_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P3__ap_avg\" in X_super123.columns:\n",
    "    X_super123[\"P3__ap_avg_mean\"] = X_super123[\"P3__ap_avg\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super123[\"P3__ap_avg_std\"]  = X_super123[\"P3__ap_avg\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super123[\"P3__ap_avg_min\"]  = X_super123[\"P3__ap_avg\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super123[\"P3__ap_avg_max\"]  = X_super123[\"P3__ap_avg\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "\n",
    "if \"P3__ap_psth\" in X_super123.columns:\n",
    "    X_super123[\"P3__ap_psth_mean\"] = X_super123[\"P3__ap_psth\"].apply(lambda v: np.mean(v) if v.size else np.nan)\n",
    "    X_super123[\"P3__ap_psth_std\"]  = X_super123[\"P3__ap_psth\"].apply(lambda v: np.std(v)  if v.size else np.nan)\n",
    "    X_super123[\"P3__ap_psth_min\"]  = X_super123[\"P3__ap_psth\"].apply(lambda v: np.min(v)  if v.size else np.nan)\n",
    "    X_super123[\"P3__ap_psth_max\"]  = X_super123[\"P3__ap_psth\"].apply(lambda v: np.max(v)  if v.size else np.nan)\n",
    "# Drop original vector columns\n",
    "\n",
    "\n",
    "if vec_cols:\n",
    "    X_super123 = X_super123.drop(columns=vec_cols)\n",
    "\n",
    "\n",
    "# --- Part1 NaN handling for ap_duration (median fill), consistent with earlier logic ---\n",
    "if \"P1__ap_duration\" in X_super123.columns and X_super123[\"P1__ap_duration\"].isna().any():\n",
    "    X_super123.loc[:, \"P1__ap_duration\"] = X_super123[\"P1__ap_duration\"].fillna(\n",
    "        X_super123[\"P1__ap_duration\"].median()\n",
    "    )\n",
    "\n",
    "# --- Drop rows with any NaN and align labels (same as Part2/super logic) ---\n",
    "mask = X_super123.notna().all(axis=1)\n",
    "X_super123 = X_super123.loc[mask].copy()\n",
    "y_super123 = y_super123[mask.values]\n",
    "\n",
    "print(\"Superdataset (Part1+Part2+Part3) shape after preprocessing:\", X_super123.shape)\n",
    "\n",
    "# --- Split and evaluate all models on Part1+Part2+Part3 ---\n",
    "X_trainS123, X_testS123, y_trainS123, y_testS123 = train_test_split(\n",
    "    X_super123, y_super123, test_size=0.2, stratify=y_super123, random_state=42\n",
    ")\n",
    "\n",
    "for model_name, model in models:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {model_name}\")\n",
    "    print('='*60)\n",
    "\n",
    "    res, _ = evaluate_model(\n",
    "        model, X_trainS123, X_testS123, y_trainS123, y_testS123,\n",
    "        dataset_name=\"Part1+Part2+Part3\", scale=True\n",
    "    )\n",
    "    all_results.append(res)\n",
    "    print(f\"Accuracy: {res['accuracy']:.3f}, F1-macro: {res['f1_macro']:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(\"SUMMARY OF ALL RESULTS:\")\n",
    "print(results_df[['dataset', 'model', 'accuracy', 'f1_macro', 'n_features']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIO482",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
