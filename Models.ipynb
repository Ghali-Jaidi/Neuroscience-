{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b741cf03",
   "metadata": {},
   "source": [
    "# Training and testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a953d",
   "metadata": {},
   "source": [
    "We train and test different models that perform classification tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26b0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "#%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9116c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a47571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Part1_Results: (232, 9)\n",
      "Loaded Part2_Results: (232, 16)\n",
      "Loaded Part3_Results: (134, 16)\n"
     ]
    }
   ],
   "source": [
    "base_dir = '.' \n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "files = ['Part1_Results.csv', 'Part2_Results.csv', 'Part3_Results.csv']\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        # Extract name without extension for dictionary key\n",
    "        name = file.replace('.csv', '')\n",
    "        dataframes[name] = pd.read_csv(file_path, sep=';', index_col=0)\n",
    "        print(f\"Loaded {name}: {dataframes[name].shape}\")\n",
    "    else:\n",
    "        print(f\"Warning: {file} not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b9f5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = dataframes['Part1_Results'].copy()\n",
    "X_1.drop(columns=['cell_id', 'cell_type'], inplace=True)\n",
    "y_1 = dataframes['Part1_Results']['cell_type'].copy()\n",
    "label_encoder = LabelEncoder()\n",
    "y_1 = label_encoder.fit_transform(y_1)\n",
    "\n",
    "if X_1['ap_duration'].isna().any():\n",
    "    median_val = X_1['ap_duration'].median()\n",
    "    X_1.loc[:, 'ap_duration'] = X_1['ap_duration'].fillna(median_val)\n",
    "\n",
    "X_2 = dataframes['Part2_Results'].copy()\n",
    "X_2.drop(columns=['cell_id', 'cell_type'], inplace=True)\n",
    "y_2 = dataframes['Part1_Results']['cell_type'].copy()\n",
    "label_encoder = LabelEncoder()\n",
    "y_2 = label_encoder.fit_transform(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d2fb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X_1, y_1, \n",
    "    test_size=0.2, \n",
    "    stratify=y_1,  #ensures percentages of cell types are preserved\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X_2, y_2, \n",
    "    test_size=0.2, \n",
    "    stratify=y_2,  \n",
    "    random_state=42  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fff02",
   "metadata": {},
   "source": [
    "We define a function that will be used to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423f5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, dataset_name=\"\", scale=False):    \n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred, \n",
    "                                   target_names=label_encoder.classes_,\n",
    "                                   output_dict=True)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'dataset': dataset_name,\n",
    "        'model': model.__class__.__name__,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'n_features': X_train.shape[1],\n",
    "        'report': report,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1097b92",
   "metadata": {},
   "source": [
    "## Model training and testing on Part 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38628137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ea0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to train and test\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)),\n",
    "    ('SVM Linear', SVC(kernel='linear', class_weight='balanced', random_state=42)),\n",
    "    ('SVM RBF', SVC(kernel='rbf', class_weight='balanced', random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, max_depth=5, \n",
    "                                             class_weight='balanced', random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, max_depth=3, \n",
    "                                                     random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5cefa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Testing Logistic Regression-------\n",
      "Accuracy: 0.830, F1-macro: 0.789\n",
      "confusion matrix:\n",
      "[[16  0  0  1]\n",
      " [ 0  8  2  0]\n",
      " [ 2  0 12  1]\n",
      " [ 0  1  1  3]]\n",
      "-------Testing SVM Linear-------\n",
      "Accuracy: 0.851, F1-macro: 0.805\n",
      "confusion matrix:\n",
      "[[16  0  0  1]\n",
      " [ 0  8  2  0]\n",
      " [ 1  0 13  1]\n",
      " [ 0  1  1  3]]\n",
      "-------Testing SVM RBF-------\n",
      "Accuracy: 0.830, F1-macro: 0.765\n",
      "confusion matrix:\n",
      "[[17  0  0  0]\n",
      " [ 0  8  2  0]\n",
      " [ 2  0 12  1]\n",
      " [ 0  1  2  2]]\n",
      "-------Testing Random Forest-------\n",
      "Accuracy: 0.851, F1-macro: 0.782\n",
      "confusion matrix:\n",
      "[[17  0  0  0]\n",
      " [ 0  8  2  0]\n",
      " [ 1  0 13  1]\n",
      " [ 0  1  2  2]]\n",
      "-------Testing Gradient Boosting-------\n",
      "Accuracy: 0.851, F1-macro: 0.781\n",
      "confusion matrix:\n",
      "[[17  0  0  0]\n",
      " [ 0  8  2  0]\n",
      " [ 1  0 13  1]\n",
      " [ 1  1  1  2]]\n",
      "-------Testing KNN-------\n",
      "Accuracy: 0.830, F1-macro: 0.727\n",
      "confusion matrix:\n",
      "[[17  0  0  0]\n",
      " [ 0  8  2  0]\n",
      " [ 2  0 13  0]\n",
      " [ 0  1  3  1]]\n",
      "SUMMARY OF ALL RESULTS:\n",
      "  dataset                       model  accuracy  f1_macro  n_features\n",
      "0   Part1          LogisticRegression  0.829787  0.789098           7\n",
      "1   Part1                         SVC  0.851064  0.805498           7\n",
      "2   Part1                         SVC  0.829787  0.765186           7\n",
      "3   Part1      RandomForestClassifier  0.851064  0.781508           7\n",
      "4   Part1  GradientBoostingClassifier  0.851064  0.781315           7\n",
      "5   Part1        KNeighborsClassifier  0.829787  0.726940           7\n"
     ]
    }
   ],
   "source": [
    "# We test each model first on the data from Part 1\n",
    "all_results = []\n",
    "\n",
    "for model_name, model in models:\n",
    "\n",
    "    print(f\"-------Testing {model_name}-------\")\n",
    "\n",
    "    \n",
    "    res1, _ = evaluate_model(model, X_train1, X_test1, y_train1, y_test1, \n",
    "                            dataset_name=\"Part1\", scale=True)\n",
    "    all_results.append(res1)\n",
    "    print(f\"Accuracy: {res1['accuracy']:.3f}, F1-macro: {res1['f1_macro']:.3f}\")\n",
    "    print(f\"confusion matrix:\")\n",
    "    print(res1['confusion_matrix'])\n",
    "\n",
    "\n",
    "# Convert results to DataFrame for comparison\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"SUMMARY OF ALL RESULTS:\")\n",
    "\n",
    "print(results_df[['dataset', 'model', 'accuracy', 'f1_macro', 'n_features']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio482",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
