{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750ed858",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25893574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "#%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a81b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/ghalijaidi/Desktop/NSSP Projet/Neuroscience-\n",
      "Loaded Part1_Results: (232, 9)\n",
      "Loaded Part2_Results: (232, 16)\n",
      "Loaded Part3_Results: (134, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\", os.getcwd())\n",
    "base_dir = '.' \n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "files = ['Part1_Results.csv', 'Part2_Results.csv', 'Part3_Results.csv']\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        # Extract name without extension for dictionary key\n",
    "        name = file.replace('.csv', '')\n",
    "        dataframes[name] = pd.read_csv(file_path, sep=';', index_col=0)\n",
    "        print(f\"Loaded {name}: {dataframes[name].shape}\")\n",
    "    else:\n",
    "        print(f\"Warning: {file} not found!\")\n",
    "\n",
    "# To access the individual data we have to use\n",
    "# dataframes['Part1_Results']\n",
    "# dataframes['Part2_Results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2953b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 232 entries, 0 to 231\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   cell_id       232 non-null    object \n",
      " 1   cell_type     232 non-null    object \n",
      " 2   firing_rate   232 non-null    float64\n",
      " 3   ap_threshold  232 non-null    float64\n",
      " 4   ap_duration   230 non-null    float64\n",
      " 5   mean_vm       232 non-null    float64\n",
      " 6   std_vm        232 non-null    float64\n",
      " 7   fft_low       232 non-null    float64\n",
      " 8   fft_high      232 non-null    float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 18.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 232 entries, 0 to 231\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   cell_id            232 non-null    object \n",
      " 1   cell_type          232 non-null    object \n",
      " 2   numb_events        232 non-null    int64  \n",
      " 3   wp_avg             232 non-null    object \n",
      " 4   wp_amplitude_pre   227 non-null    float64\n",
      " 5   wp_amplitude_post  227 non-null    float64\n",
      " 6   vm_avg             232 non-null    object \n",
      " 7   vm_amplitude_pre   227 non-null    float64\n",
      " 8   vm_amplitude_post  227 non-null    float64\n",
      " 9   ap_avg             232 non-null    object \n",
      " 10  ap_psth            232 non-null    object \n",
      " 11  ap_fr_pre          227 non-null    float64\n",
      " 12  ap_fr_post         227 non-null    float64\n",
      " 13  delta_wp           227 non-null    float64\n",
      " 14  delta_vm           227 non-null    float64\n",
      " 15  delta_ap           227 non-null    float64\n",
      "dtypes: float64(9), int64(1), object(6)\n",
      "memory usage: 30.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 134 entries, 0 to 133\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   cell_id            134 non-null    object \n",
      " 1   cell_type          134 non-null    object \n",
      " 2   numb_events        134 non-null    int64  \n",
      " 3   wp_avg             134 non-null    object \n",
      " 4   wp_amplitude_pre   134 non-null    float64\n",
      " 5   wp_amplitude_post  134 non-null    float64\n",
      " 6   vm_avg             134 non-null    object \n",
      " 7   vm_amplitude_pre   134 non-null    float64\n",
      " 8   vm_amplitude_post  134 non-null    float64\n",
      " 9   ap_avg             134 non-null    object \n",
      " 10  ap_psth            134 non-null    object \n",
      " 11  ap_fr_pre          134 non-null    float64\n",
      " 12  ap_fr_post         134 non-null    float64\n",
      " 13  delta_wp           134 non-null    float64\n",
      " 14  delta_vm           134 non-null    float64\n",
      " 15  delta_ap           134 non-null    float64\n",
      "dtypes: float64(9), int64(1), object(6)\n",
      "memory usage: 17.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataframes['Part1_Results'].info())\n",
    "print(dataframes['Part2_Results'].info())\n",
    "print(dataframes['Part3_Results'].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c535f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check alignment of cell_id between Part1 and Part2\n",
    "for i in range(len(dataframes['Part1_Results']['cell_id'])):\n",
    "    if dataframes['Part1_Results']['cell_id'].iloc[i] != dataframes['Part2_Results']['cell_id'].iloc[i]:\n",
    "        print(\"Mismatch between part 1 and 2 in cell_id at index\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ac8287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch between part 1 and 3 in cell_id at index 0\n",
      "Mismatch between part 1 and 3 in cell_id at index 1\n",
      "Mismatch between part 1 and 3 in cell_id at index 2\n",
      "Mismatch between part 1 and 3 in cell_id at index 3\n",
      "Mismatch between part 1 and 3 in cell_id at index 4\n",
      "Mismatch between part 1 and 3 in cell_id at index 5\n",
      "Mismatch between part 1 and 3 in cell_id at index 6\n",
      "Mismatch between part 1 and 3 in cell_id at index 7\n",
      "Mismatch between part 1 and 3 in cell_id at index 8\n",
      "Mismatch between part 1 and 3 in cell_id at index 9\n",
      "Mismatch between part 1 and 3 in cell_id at index 10\n",
      "Mismatch between part 1 and 3 in cell_id at index 11\n",
      "Mismatch between part 1 and 3 in cell_id at index 12\n",
      "Mismatch between part 1 and 3 in cell_id at index 13\n",
      "Mismatch between part 1 and 3 in cell_id at index 14\n",
      "Mismatch between part 1 and 3 in cell_id at index 15\n",
      "Mismatch between part 1 and 3 in cell_id at index 16\n",
      "Mismatch between part 1 and 3 in cell_id at index 17\n",
      "Mismatch between part 1 and 3 in cell_id at index 18\n",
      "Mismatch between part 1 and 3 in cell_id at index 19\n",
      "Mismatch between part 1 and 3 in cell_id at index 20\n",
      "Mismatch between part 1 and 3 in cell_id at index 21\n",
      "Mismatch between part 1 and 3 in cell_id at index 22\n",
      "Mismatch between part 1 and 3 in cell_id at index 23\n",
      "Mismatch between part 1 and 3 in cell_id at index 24\n",
      "Mismatch between part 1 and 3 in cell_id at index 25\n",
      "Mismatch between part 1 and 3 in cell_id at index 26\n",
      "Mismatch between part 1 and 3 in cell_id at index 27\n",
      "Mismatch between part 1 and 3 in cell_id at index 28\n",
      "Mismatch between part 1 and 3 in cell_id at index 29\n",
      "Mismatch between part 1 and 3 in cell_id at index 30\n",
      "Mismatch between part 1 and 3 in cell_id at index 31\n",
      "Mismatch between part 1 and 3 in cell_id at index 32\n",
      "Mismatch between part 1 and 3 in cell_id at index 33\n",
      "Mismatch between part 1 and 3 in cell_id at index 34\n",
      "Mismatch between part 1 and 3 in cell_id at index 35\n",
      "Mismatch between part 1 and 3 in cell_id at index 36\n",
      "Mismatch between part 1 and 3 in cell_id at index 37\n",
      "Mismatch between part 1 and 3 in cell_id at index 38\n",
      "Mismatch between part 1 and 3 in cell_id at index 39\n",
      "Mismatch between part 1 and 3 in cell_id at index 40\n",
      "Mismatch between part 1 and 3 in cell_id at index 41\n",
      "Mismatch between part 1 and 3 in cell_id at index 42\n",
      "Mismatch between part 1 and 3 in cell_id at index 43\n",
      "Mismatch between part 1 and 3 in cell_id at index 44\n",
      "Mismatch between part 1 and 3 in cell_id at index 45\n",
      "Mismatch between part 1 and 3 in cell_id at index 46\n",
      "Mismatch between part 1 and 3 in cell_id at index 47\n",
      "Mismatch between part 1 and 3 in cell_id at index 48\n",
      "Mismatch between part 1 and 3 in cell_id at index 49\n",
      "Mismatch between part 1 and 3 in cell_id at index 50\n",
      "Mismatch between part 1 and 3 in cell_id at index 51\n",
      "Mismatch between part 1 and 3 in cell_id at index 52\n",
      "Mismatch between part 1 and 3 in cell_id at index 53\n",
      "Mismatch between part 1 and 3 in cell_id at index 54\n",
      "Mismatch between part 1 and 3 in cell_id at index 55\n",
      "Mismatch between part 1 and 3 in cell_id at index 56\n",
      "Mismatch between part 1 and 3 in cell_id at index 57\n",
      "Mismatch between part 1 and 3 in cell_id at index 58\n",
      "Mismatch between part 1 and 3 in cell_id at index 59\n",
      "Mismatch between part 1 and 3 in cell_id at index 60\n",
      "Mismatch between part 1 and 3 in cell_id at index 61\n",
      "Mismatch between part 1 and 3 in cell_id at index 62\n",
      "Mismatch between part 1 and 3 in cell_id at index 63\n",
      "Mismatch between part 1 and 3 in cell_id at index 64\n",
      "Mismatch between part 1 and 3 in cell_id at index 65\n",
      "Mismatch between part 1 and 3 in cell_id at index 66\n",
      "Mismatch between part 1 and 3 in cell_id at index 67\n",
      "Mismatch between part 1 and 3 in cell_id at index 68\n",
      "Mismatch between part 1 and 3 in cell_id at index 69\n",
      "Mismatch between part 1 and 3 in cell_id at index 70\n",
      "Mismatch between part 1 and 3 in cell_id at index 71\n",
      "Mismatch between part 1 and 3 in cell_id at index 72\n",
      "Mismatch between part 1 and 3 in cell_id at index 73\n",
      "Mismatch between part 1 and 3 in cell_id at index 74\n",
      "Mismatch between part 1 and 3 in cell_id at index 75\n",
      "Mismatch between part 1 and 3 in cell_id at index 76\n",
      "Mismatch between part 1 and 3 in cell_id at index 77\n",
      "Mismatch between part 1 and 3 in cell_id at index 78\n",
      "Mismatch between part 1 and 3 in cell_id at index 79\n",
      "Mismatch between part 1 and 3 in cell_id at index 80\n",
      "Mismatch between part 1 and 3 in cell_id at index 81\n",
      "Mismatch between part 1 and 3 in cell_id at index 82\n",
      "Mismatch between part 1 and 3 in cell_id at index 83\n",
      "Mismatch between part 1 and 3 in cell_id at index 84\n",
      "Mismatch between part 1 and 3 in cell_id at index 85\n",
      "Mismatch between part 1 and 3 in cell_id at index 86\n",
      "Mismatch between part 1 and 3 in cell_id at index 87\n",
      "Mismatch between part 1 and 3 in cell_id at index 88\n",
      "Mismatch between part 1 and 3 in cell_id at index 89\n",
      "Mismatch between part 1 and 3 in cell_id at index 90\n",
      "Mismatch between part 1 and 3 in cell_id at index 91\n",
      "Mismatch between part 1 and 3 in cell_id at index 92\n",
      "Mismatch between part 1 and 3 in cell_id at index 93\n",
      "Mismatch between part 1 and 3 in cell_id at index 94\n",
      "Mismatch between part 1 and 3 in cell_id at index 95\n",
      "Mismatch between part 1 and 3 in cell_id at index 96\n",
      "Mismatch between part 1 and 3 in cell_id at index 97\n",
      "Mismatch between part 1 and 3 in cell_id at index 98\n",
      "Mismatch between part 1 and 3 in cell_id at index 99\n",
      "Mismatch between part 1 and 3 in cell_id at index 100\n",
      "Mismatch between part 1 and 3 in cell_id at index 101\n",
      "Mismatch between part 1 and 3 in cell_id at index 102\n",
      "Mismatch between part 1 and 3 in cell_id at index 103\n",
      "Mismatch between part 1 and 3 in cell_id at index 104\n",
      "Mismatch between part 1 and 3 in cell_id at index 105\n",
      "Mismatch between part 1 and 3 in cell_id at index 106\n",
      "Mismatch between part 1 and 3 in cell_id at index 107\n",
      "Mismatch between part 1 and 3 in cell_id at index 108\n",
      "Mismatch between part 1 and 3 in cell_id at index 109\n",
      "Mismatch between part 1 and 3 in cell_id at index 110\n",
      "Mismatch between part 1 and 3 in cell_id at index 111\n",
      "Mismatch between part 1 and 3 in cell_id at index 112\n",
      "Mismatch between part 1 and 3 in cell_id at index 113\n",
      "Mismatch between part 1 and 3 in cell_id at index 114\n",
      "Mismatch between part 1 and 3 in cell_id at index 115\n",
      "Mismatch between part 1 and 3 in cell_id at index 116\n",
      "Mismatch between part 1 and 3 in cell_id at index 117\n",
      "Mismatch between part 1 and 3 in cell_id at index 118\n",
      "Mismatch between part 1 and 3 in cell_id at index 119\n",
      "Mismatch between part 1 and 3 in cell_id at index 120\n",
      "Mismatch between part 1 and 3 in cell_id at index 121\n",
      "Mismatch between part 1 and 3 in cell_id at index 122\n",
      "Mismatch between part 1 and 3 in cell_id at index 123\n",
      "Mismatch between part 1 and 3 in cell_id at index 124\n",
      "Mismatch between part 1 and 3 in cell_id at index 125\n",
      "Mismatch between part 1 and 3 in cell_id at index 126\n",
      "Mismatch between part 1 and 3 in cell_id at index 127\n",
      "Mismatch between part 1 and 3 in cell_id at index 128\n",
      "Mismatch between part 1 and 3 in cell_id at index 129\n",
      "Mismatch between part 1 and 3 in cell_id at index 130\n",
      "Mismatch between part 1 and 3 in cell_id at index 131\n",
      "Mismatch between part 1 and 3 in cell_id at index 132\n",
      "Mismatch between part 1 and 3 in cell_id at index 133\n"
     ]
    }
   ],
   "source": [
    "# Check alignment of cell_id between Part1 and Part3\n",
    "for i in range(len(dataframes['Part3_Results']['cell_id'])):\n",
    "    if dataframes['Part1_Results']['cell_id'].iloc[i] != dataframes['Part3_Results']['cell_id'].iloc[i]:\n",
    "        print(\"Mismatch between part 1 and 3 in cell_id at index\", i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1472feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 cell_id(s) from Part3 not found in Part1. Examples: ['SC914_1', 'TK390_1', 'SC915_1', 'SC903_1', 'TK358_3', 'SC909_1', 'SC913_1', 'SC907_1']\n"
     ]
    }
   ],
   "source": [
    "#Checking whether the cells are only misaligned or entirely different.\n",
    "\n",
    "part1_ids = set(dataframes['Part1_Results']['cell_id'])\n",
    "part3_ids = set(dataframes['Part3_Results']['cell_id'])\n",
    "\n",
    "missing_in_part1 = [cid for cid in part3_ids if cid not in part1_ids]\n",
    "\n",
    "if missing_in_part1:\n",
    "    print(f\"{len(missing_in_part1)} cell_id(s) from Part3 not found in Part1. Examples: {missing_in_part1[:10]}\")\n",
    "else:\n",
    "    print(\"All Part3 cell_ids are present in Part1.\")        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe51a3",
   "metadata": {},
   "source": [
    "What we conclude from this is that Part 3 recordings concern mostly a subset of part 1&2 cells. On top of that, 8 of the cells present in part 3 are entirely absent from part 1 and 2. Other than that, the misalignments of the indeces do not mean that all cell are entirely new, the dataframe simply shows a different order. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6529e33",
   "metadata": {},
   "source": [
    "Let's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05e11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping:\n",
      "  EXC -> 0\n",
      "  PV -> 1\n",
      "  SST -> 2\n",
      "  VIP -> 3\n",
      "\n",
      "Encoded y1 shape: (232,)\n",
      "\n",
      "Encoded y2 shape: (232,)\n",
      "\n",
      "Encoded y3 shape: (134,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/opt/anaconda3/envs/BIO482/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y1 = dataframes['Part1_Results'][['cell_type']].copy()\n",
    "y2 = dataframes['Part2_Results'][['cell_type']].copy()\n",
    "y3 = dataframes['Part3_Results'][['cell_type']].copy()\n",
    "\n",
    "\n",
    "\n",
    "y1.head()\n",
    "y2.head()\n",
    "y3.head()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y1_encoded = label_encoder.fit_transform(y1)\n",
    "y2_encoded = label_encoder.transform(y2)\n",
    "y3_encoded = label_encoder.transform(y3)\n",
    "\n",
    "# See the mapping\n",
    "print(\"Label mapping:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {label} -> {i}\")\n",
    "\n",
    "print(f\"\\nEncoded y1 shape: {y1_encoded.shape}\")\n",
    "print(f\"\\nEncoded y2 shape: {y2_encoded.shape}\")\n",
    "print(f\"\\nEncoded y3 shape: {y3_encoded.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb67bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Type Distribution\n",
      "EXC        86         37.07%\n",
      "SST        72         31.03%\n",
      "PV         49         21.12%\n",
      "VIP        25         10.78%\n",
      "Total cells: 232\n"
     ]
    }
   ],
   "source": [
    "# We check if there is class imbalance \n",
    "value_counts = dataframes['Part1_Results']['cell_type'].value_counts()\n",
    "percentages = dataframes['Part1_Results']['cell_type'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Cell Type Distribution\")\n",
    "\n",
    "for cell_type in value_counts.index:\n",
    "    count = value_counts[cell_type]\n",
    "    pct = percentages[cell_type]\n",
    "    print(f\"{cell_type:<10} {count:<10} {pct:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"Total cells: {len(dataframes['Part1_Results'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384c4906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Type Distribution\n",
      "EXC        86         37.07%\n",
      "SST        72         31.03%\n",
      "PV         49         21.12%\n",
      "VIP        25         10.78%\n",
      "Total cells: 232\n"
     ]
    }
   ],
   "source": [
    "#Same check for part 2\n",
    "value_counts = dataframes['Part2_Results']['cell_type'].value_counts()\n",
    "percentages = dataframes['Part2_Results']['cell_type'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Cell Type Distribution\")\n",
    "\n",
    "for cell_type in value_counts.index:\n",
    "    count = value_counts[cell_type]\n",
    "    pct = percentages[cell_type]\n",
    "    print(f\"{cell_type:<10} {count:<10} {pct:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"Total cells: {len(dataframes['Part2_Results'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2acf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Type Distribution\n",
      "EXC        67         50.00%\n",
      "SST        37         27.61%\n",
      "PV         22         16.42%\n",
      "VIP        8          5.97%\n",
      "Total cells: 134\n"
     ]
    }
   ],
   "source": [
    "#Same check for part 3 : \n",
    "value_counts = dataframes['Part3_Results']['cell_type'].value_counts()\n",
    "percentages = dataframes['Part3_Results']['cell_type'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Cell Type Distribution\")\n",
    "\n",
    "for cell_type in value_counts.index:\n",
    "    count = value_counts[cell_type]\n",
    "    pct = percentages[cell_type]\n",
    "    print(f\"{cell_type:<10} {count:<10} {pct:.2f}%\")\n",
    "\n",
    "print(f\"Total cells: {len(dataframes['Part3_Results'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec4636",
   "metadata": {},
   "source": [
    "Part 3 shows a very different distribution of cell types compared to part 1 and 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2fec7a",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af241094",
   "metadata": {},
   "source": [
    "Let's say we want to build 3 models first, one for each dataset, and then one big supermodel which would include all features across datasets merged on cell_id. The goal is to compare the accuracy of all our different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20dfb522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1 shape: (232, 7)\n",
      "y1_encoded shape: (232,)\n",
      "Training set size: 185\n",
      "Test set size: 47\n",
      "X_2 shape: (232, 14)\n",
      "Training set size: 185\n",
      "Test set size: 47\n",
      "X_3 shape: (134, 14)\n",
      "Training set size: 107\n",
      "Test set size: 27\n"
     ]
    }
   ],
   "source": [
    "# We start by training on Part 1 features \n",
    "X_1 = dataframes['Part1_Results'].copy()\n",
    "X_1.drop(columns=['cell_id', 'cell_type'], inplace=True)\n",
    "\n",
    "print(f\"X_1 shape: {X_1.shape}\")\n",
    "print(f\"y1_encoded shape: {y1_encoded.shape}\")\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X_1, y1_encoded, \n",
    "    test_size=0.2, \n",
    "    stratify=y1_encoded,  #ensures percentages of cell types are preserved\n",
    "    random_state=42  \n",
    ")\n",
    "print(f\"Training set size: {len(X_train1)}\")\n",
    "print(f\"Test set size: {len(X_test1)}\")\n",
    "\n",
    "X_2 = dataframes['Part2_Results'].copy()\n",
    "X_2.drop(columns=['cell_id', 'cell_type'], inplace=True)\n",
    "\n",
    "print(f\"X_2 shape: {X_2.shape}\")\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X_2, y2_encoded, \n",
    "    test_size=0.2, \n",
    "    stratify=y2_encoded,  #ensures percentages of cell types are preserved\n",
    "    random_state=42  \n",
    ")\n",
    "print(f\"Training set size: {len(X_train2)}\")\n",
    "print(f\"Test set size: {len(X_test2)}\")\n",
    "\n",
    "X_3 = dataframes['Part3_Results'].copy()\n",
    "X_3.drop(columns=['cell_id', 'cell_type'], inplace=True)\n",
    "print(f\"X_3 shape: {X_3.shape}\")\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(\n",
    "    X_3, y3_encoded, \n",
    "    test_size=0.2, \n",
    "    stratify=y3_encoded,  #ensures percentages of cell types are preserved\n",
    "    random_state=42  \n",
    ")\n",
    "print(f\"Training set size: {len(X_train3)}\")\n",
    "print(f\"Test set size: {len(X_test3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIO482",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
